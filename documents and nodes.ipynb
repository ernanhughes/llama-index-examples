{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex Bottoms-Up Development - Documents and Nodes\n",
    "In order to answer questions about the LlamaIndex docs, we first need to load them!\n",
    "\n",
    "A majority of our documentation is in markdown format. For the sake of scope, we will ONLY worry about markdown files for now.\n",
    "\n",
    "When parsing these files, there are a few things we might want to keep track of\n",
    "\n",
    "- Current header (and header hierarchy!)\n",
    "- Code blocks\n",
    "- Text\n",
    "- Source file names\n",
    "\n",
    "While LlamaIndex does have a built-in markdown loader, we can write our own to fit our requirements exactly! Loaders are not magic -- they just read files and create documents. So building our own is easy!\n",
    "\n",
    "We have provided an implementation of a custom markdown loaded in the source code. Let's test it out to see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.file import MarkdownReader\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "def load_markdown_docs(filepath):\n",
    "    \"\"\"Load markdown docs from a directory, excluding all other file types.\"\"\"\n",
    "    loader = SimpleDirectoryReader(\n",
    "        input_dir=filepath, \n",
    "        exclude=[\"*.rst\", \"*.ipynb\", \"*.py\", \"*.bat\", \"*.txt\", \"*.png\", \"*.jpg\", \"*.jpeg\", \"*.csv\", \"*.html\", \"*.js\", \"*.css\", \"*.pdf\", \"*.json\"],\n",
    "        file_extractor={\".md\": MarkdownReader()},\n",
    "        recursive=True\n",
    "    )\n",
    "\n",
    "    return loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our documents from each folder.\n",
    "# we keep them seperate for now, in order to create seperate indexes later\n",
    "getting_started_docs = load_markdown_docs(\"data/getting_started\")\n",
    "community_docs = load_markdown_docs(\"data/community\")\n",
    "data_docs = load_markdown_docs(\"data/core_modules/data_modules\")\n",
    "agent_docs = load_markdown_docs(\"data/core_modules/agent_modules\")\n",
    "model_docs = load_markdown_docs(\"data/core_modules/model_modules\")\n",
    "query_docs = load_markdown_docs(\"data/core_modules/query_modules\")\n",
    "supporting_docs = load_markdown_docs(\"data/core_modules/supporting_modules\")\n",
    "tutorials_docs = load_markdown_docs(\"data/end_to_end_tutorials\")\n",
    "contributing_docs = load_markdown_docs(\"data/development\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our printing look nice\n",
    "from llama_index.core.schema import MetadataMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path: b:\\projects\\llama-index-examples\\data\\core_modules\\agent_modules\\agents\\root.md\n",
      "file_name: root.md\n",
      "file_size: 2409\n",
      "creation_date: 2024-06-26\n",
      "last_modified_date: 2024-06-26\n",
      "\n",
      "\n",
      "\n",
      "Reasoning Loop\n",
      "The reasoning loop depends on the type of agent. We have support for the following agents: \n",
      "- OpenAI Function agent (built on top of the OpenAI Function API)\n",
      "- a ReAct agent (which works across any chat/text completion endpoint).\n"
     ]
    }
   ],
   "source": [
    "print(agent_docs[5].get_content(metadata_mode=MetadataMode.ALL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': 'b:\\\\projects\\\\llama-index-examples\\\\data\\\\core_modules\\\\agent_modules\\\\agents\\\\modules.md', 'file_name': 'modules.md', 'file_size': 646, 'creation_date': '2024-06-26', 'last_modified_date': '2024-06-26'}\n"
     ]
    }
   ],
   "source": [
    "print(agent_docs[0].metadata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks not bad! We can see that we have metadata, as well as nicely formatted content.\n",
    "\n",
    "But, we can improve the formatting even further! We can provide better templating, so that the LLM and embedding models can get a better idea of what they are reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_template = \"Content Metadata:\\n{metadata_str}\\n\\nContent:\\n{content}\"\n",
    "\n",
    "metadata_template = \"{key}: {value},\"\n",
    "metadata_seperator= \" \"\n",
    "\n",
    "for doc in agent_docs:\n",
    "    doc.text_template = text_template\n",
    "    doc.metadata_template = metadata_template\n",
    "    doc.metadata_seperator = metadata_seperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Metadata:\n",
      "file_path: b:\\projects\\llama-index-examples\\data\\core_modules\\agent_modules\\agents\\modules.md, file_name: modules.md, file_size: 646, creation_date: 2024-06-26, last_modified_date: 2024-06-26,\n",
      "\n",
      "Content:\n",
      "\n",
      "\n",
      "Module Guides\n",
      "\n",
      "These guide provide an overview of how to use our agent classes.\n",
      "\n",
      "For more detailed guides on how to use specific tools, check out our tools module guides.\n"
     ]
    }
   ],
   "source": [
    "print(agent_docs[0].get_content(metadata_mode=MetadataMode.ALL))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Customization\n",
    "Going even further with metadata, we can also customize which metadata fields will be seen by both the embedding model and LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Metadata:\n",
      "file_path: b:\\projects\\llama-index-examples\\data\\core_modules\\agent_modules\\agents\\modules.md, file_name: modules.md, file_size: 646, creation_date: 2024-06-26, last_modified_date: 2024-06-26,\n",
      "\n",
      "Content:\n",
      "\n",
      "\n",
      "Module Guides\n",
      "\n",
      "These guide provide an overview of how to use our agent classes.\n",
      "\n",
      "For more detailed guides on how to use specific tools, check out our tools module guides.\n"
     ]
    }
   ],
   "source": [
    "# Hide the File Name from the LLM\n",
    "agent_docs[0].excluded_llm_metadata_keys = [\"File Name\"]\n",
    "print(agent_docs[0].get_content(metadata_mode=MetadataMode.LLM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Metadata:\n",
      "file_path: b:\\projects\\llama-index-examples\\data\\core_modules\\agent_modules\\agents\\modules.md, file_name: modules.md, file_size: 646, creation_date: 2024-06-26, last_modified_date: 2024-06-26,\n",
      "\n",
      "Content:\n",
      "\n",
      "\n",
      "Module Guides\n",
      "\n",
      "These guide provide an overview of how to use our agent classes.\n",
      "\n",
      "For more detailed guides on how to use specific tools, check out our tools module guides.\n"
     ]
    }
   ],
   "source": [
    "# Hide the File Name from the embedding model\n",
    "agent_docs[0].excluded_embed_metadata_keys = [\"File Name\"]\n",
    "print(agent_docs[0].get_content(metadata_mode=MetadataMode.EMBED))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we covered how to use a custom data loader, as well as how to customize the text representations of your data when including metadata for both LLMs and embedding models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
