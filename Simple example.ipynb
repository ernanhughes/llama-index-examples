{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first document discusses ancient Rome, highlighting its grand architecture, skilled engineering, Roman Republic governance, and the lasting influence of Roman civilization on modern societies. The second document focuses on dogs as loyal companions, describing their various breeds, unique traits, and the joy and comfort they bring to people's lives as beloved pets.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"summarize each document in a few sentences\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 1\n",
      "Text: The quick brown fox jumps over the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "doc = Document(\n",
    "    text=text, \n",
    "    metadata={'author': 'John Doe','category': 'others'}, \n",
    "    id_='1'\n",
    ")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<NodeRelationship.NEXT: '3'>: 'ea55eee2-1e30-471f-8848-0ff3bf9be754'}\n",
      "{<NodeRelationship.PREVIOUS: '2'>: 'fd6689fa-7684-498c-a244-25d7703c366c'}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.schema import (\n",
    "    TextNode, \n",
    "    NodeRelationship\n",
    ")\n",
    "doc = Document(text=\"First sentence. Second Sentence\")\n",
    "n1 = TextNode(text=\"First sentence\", node_id=doc.doc_id)\n",
    "n2 = TextNode(text=\"Second sentence\", node_id=doc.doc_id)\n",
    "\n",
    "n1.relationships[NodeRelationship.NEXT] = n2.node_id \n",
    "n2.relationships[NodeRelationship.PREVIOUS] = n1.node_id\n",
    "print(n1.relationships)\n",
    "print(n2.relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 3895458c-6553-4df2-a6e3-40722a2c6680\n",
      "Text: This is a sample\n",
      "Node ID: 719892ed-c4fc-418a-88d4-2fa624cac442\n",
      "Text: document text\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "doc = Document(text=\"This is a sample document text\")\n",
    "n1 = TextNode(text=doc.text[0:16], doc_id=doc.id_) \n",
    "n2 = TextNode(text=doc.text[17:30], doc_id=doc.id_)\n",
    "print(n1)\n",
    "print(n2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messi's hometown is Rosario.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.settings import Settings\n",
    "Settings.llm = OpenAI(temperature=0.8, model=\"gpt-4\")\n",
    "\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core import SummaryIndex\n",
    "\n",
    "nodes = [\n",
    "  TextNode(text=\"Lionel Messi's hometown is Rosario.\"),\n",
    "  TextNode(text=\"He was born on June 24, 1987.\")\n",
    "]\n",
    "index = SummaryIndex(nodes)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\n",
    "    \"What is Messi's hometown?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravity is the force that attracts objects with mass towards each other.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    temperature=0.2, \n",
    "    max_tokens=50,\n",
    "    additional_kwargs={\n",
    "        \"seed\": 12345678,\n",
    "        \"top_p\": 0.5\n",
    "    }\n",
    ")\n",
    "response = llm.complete(\n",
    "    \"Explain the concept of gravity in one sentence\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length (6) is close to chunk size (12). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "This is sentence 1.\n",
      "{'author': 'John Smith'}\n",
      "This is sentence 2.\n",
      "{'author': 'John Smith'}\n",
      "Sentence 3 here.\n",
      "{'author': 'John Smith'}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "doc = Document( \n",
    "    text=(\n",
    "    \"This is sentence 1. This is sentence 2. \"\n",
    "    \"Sentence 3 here.\"\n",
    "    ),\n",
    "    metadata={\"author\": \"John Smith\"}\n",
    ")  \n",
    "splitter = TokenTextSplitter( \n",
    "    chunk_size=12, \n",
    "    chunk_overlap=0, \n",
    "    separator=\" \"\n",
    ") \n",
    "\n",
    "nodes = splitter.get_nodes_from_documents([doc]) \n",
    "for node in nodes: \n",
    "    print(node.text) \n",
    "    print(node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length (10) is close to chunk size (12). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "This is\n",
      "{'author': 'John Smith', 'tester': 'Jimmy'}\n",
      "sentence\n",
      "{'author': 'John Smith', 'tester': 'Jimmy'}\n",
      "1.\n",
      "{'author': 'John Smith', 'tester': 'Jimmy'}\n",
      "This is\n",
      "{'author': 'John Smith', 'tester': 'Jimmy'}\n",
      "sentence\n",
      "{'author': 'John Smith', 'tester': 'Jimmy'}\n",
      "2.\n",
      "{'author': 'John Smith', 'tester': 'Jimmy'}\n",
      "Sentence\n",
      "{'author': 'John Smith', 'tester': 'Jimmy'}\n",
      "3\n",
      "{'author': 'John Smith', 'tester': 'Jimmy'}\n",
      "here.\n",
      "{'author': 'John Smith', 'tester': 'Jimmy'}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "doc = Document(text=(\"This is sentence 1. This is sentence 2. \"\n",
    "    \"Sentence 3 here.\"),\n",
    "    metadata={\"author\": \"John Smith\", \"tester\" : \"Jimmy\"}\n",
    ")\n",
    "splitter = TokenTextSplitter(\n",
    "    chunk_size=12,\n",
    "    chunk_overlap=0,\n",
    "    separator=\" \"\n",
    "    )\n",
    "nodes = splitter.get_nodes_from_documents([doc])\n",
    "for node in nodes:\n",
    "    print(node.text)\n",
    "    print(node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<NodeRelationship.NEXT: '3'>: '284d5dcb-e360-4bf0-8d0e-6940bf03ab8f'}\n",
      "{<NodeRelationship.PREVIOUS: '2'>: '78103e07-3226-4b2e-8bd9-47a12f1b3346'}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.schema import (\n",
    "    TextNode,\n",
    "    NodeRelationship,\n",
    "    RelatedNodeInfo\n",
    "    )\n",
    "doc = Document(text=\"First sentence. Second Sentence\")\n",
    "n1 = TextNode(text=\"First sentence\", node_id=doc.doc_id)\n",
    "n2 = TextNode(text=\"Second sentence\", node_id=doc.doc_id)\n",
    "n1.relationships[NodeRelationship.NEXT] = n2.node_id\n",
    "n2.relationships[NodeRelationship.PREVIOUS] = n1.node_id\n",
    "print(n1.relationships)\n",
    "print(n2.relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.list.base.SummaryIndex at 0x1d86464af90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SummaryIndex, Document\n",
    "from llama_index.core.schema import TextNode\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=\"Lionel Messi is a football player from Argentina.\"\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"He has won the Ballon d'Or trophy 7 times.\"\n",
    "    ),\n",
    "    TextNode(text=\"Lionel Messi's hometown is Rosario.\"),\n",
    "    TextNode(text=\"He was born on June 24, 1987.\")\n",
    "]\n",
    "index = SummaryIndex(nodes)\n",
    "index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
